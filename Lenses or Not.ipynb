{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcEntropy(dataSet):\n",
    "    # how many entries\n",
    "    numEntries = len(dataSet)\n",
    "    # create a dict to store the label counts\n",
    "    labelCounts = {}\n",
    "    # iterate the dataset\n",
    "    for featureVector in dataSet:\n",
    "        # the last term in featureVecot is the label\n",
    "        label = featureVector[-1]\n",
    "        # if label not in labelCounts, then initialize it\n",
    "        if label not in labelCounts:\n",
    "            labelCounts[label] = 0\n",
    "        labelCounts[label] += 1\n",
    "    \n",
    "    # based on the label counts, calculate the Entropy\n",
    "    entropy = 0.0\n",
    "    for key in labelCounts:\n",
    "        prob = float(labelCounts[key]) / numEntries\n",
    "        entropy -= prob * log(prob, 2)\n",
    "    \n",
    "    # return the entropy for the dataset\n",
    "    return entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitDataSet(dataset, index, value):\n",
    "    \"\"\"\n",
    "    dataset: the given data set\n",
    "    index: the column index that is selected feature to split the data\n",
    "    value: the target value\n",
    "    \"\"\"\n",
    "    dataset_new =[]\n",
    "    for record in dataset:\n",
    "        if record[index] == value:\n",
    "            record_new = record[:index]\n",
    "            record_new.extend(record[index+1:])\n",
    "            dataset_new.append(record_new)\n",
    "    return dataset_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FindBestFeature(dataset):\n",
    "    numFeatures = len(dataset[0]) - 1\n",
    "    baseEntropy = calcEntropy(dataset)\n",
    "    maxInfoGain = 0.0\n",
    "    bestFeature = -1\n",
    "    for index in range(numFeatures):\n",
    "        subEntropy = 0.0\n",
    "        values = set([record[index] for record in dataset])\n",
    "        for value in values:\n",
    "            dataset_sub = splitDataSet(dataset, index, value)\n",
    "            prob = len(dataset_sub) / numFeatures\n",
    "            subEntropy -= calcEntropy(dataset_sub)*prob\n",
    "        infoGain = baseEntropy - subEntropy\n",
    "    \n",
    "        if (infoGain > maxInfoGain):\n",
    "            maxInfoGain = infoGain\n",
    "            bestFeature = index\n",
    "        \n",
    "    print('Info Gain is: ', infoGain, 'Best Feature index is: ', bestFeature, baseEntropy, subEntropy)\n",
    "    \n",
    "    return bestFeature\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createTree(dataset, FeatureNames):\n",
    "    labelList = [record[-1] for record in dataset]\n",
    "    # there are two stop criterion \n",
    "    # 1. when there is no other class lable\n",
    "    if labelList.count(labelList[0]) == len(labelList):\n",
    "        return labelList[0]\n",
    "    # 2. when all features are used but there are more than one labels in the dataset\n",
    "    if len(dataset[0]) == 1:\n",
    "        return majorityLabel(labelList)\n",
    "    \n",
    "    # otherwise, we have to find the best feature to split the data set\n",
    "    bestFeatureIndex = FindBestFeature(dataset)\n",
    "    bestFeatureName = FeatureNames[bestFeatureIndex]\n",
    "    \n",
    "    # initialize the tree\n",
    "    myTree = {bestFeatureName:{}}\n",
    "    del(FeatureNames[bestFeatureIndex])\n",
    "    \n",
    "    # create sub trees for this feature with different values\n",
    "    featureValues = [record[bestFeatureIndex] for record in dataset]\n",
    "    featureValues = set(featureValues)\n",
    "    for value in featureValues:\n",
    "        subFeatures = FeatureNames[:]    \n",
    "        myTree[bestFeatureName][value] = createTree(splitDataSet(dataset, bestFeatureIndex, value), subFeatures)\n",
    "    \n",
    "    return myTree\n",
    "    \n",
    "def majorityLabel(labelList):\n",
    "    LableCount = {}\n",
    "    for label in labelList:\n",
    "        if label not in labelCount:\n",
    "            labelCount[label] = 0\n",
    "        labelCount[count] += 1\n",
    "    labelCount_sorted = sorted(classCount.iteritms(), key=operator.itemgetter(1), reverse = True)\n",
    "    \n",
    "    return labelCount_sorted[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Info Gain is:  5.989843033377697 Best Feature index is:  0 1.3260875253642983 -4.6637555080133986\n",
      "Info Gain is:  2.833333333333333 Best Feature index is:  0 1.5 -1.3333333333333333\n",
      "Info Gain is:  2.5 Best Feature index is:  0 1.5 -1.0\n",
      "Info Gain is:  1.0 Best Feature index is:  0 1.0 0.0\n",
      "Info Gain is:  1.0 Best Feature index is:  0 1.0 0.0\n",
      "Info Gain is:  2.5 Best Feature index is:  0 1.5 -1.0\n",
      "Info Gain is:  1.0 Best Feature index is:  0 1.0 0.0\n",
      "Info Gain is:  1.0 Best Feature index is:  0 1.0 0.0\n",
      "Info Gain is:  3.061278124459133 Best Feature index is:  0 1.061278124459133 -2.0\n",
      "Info Gain is:  1.811278124459133 Best Feature index is:  0 0.8112781244591328 -1.0\n",
      "Info Gain is:  1.0 Best Feature index is:  0 1.0 0.0\n",
      "Info Gain is:  1.811278124459133 Best Feature index is:  0 0.8112781244591328 -1.0\n",
      "Info Gain is:  1.0 Best Feature index is:  0 1.0 0.0\n",
      "Info Gain is:  3.2987949406953985 Best Feature index is:  0 1.2987949406953985 -2.0\n",
      "Info Gain is:  2.5 Best Feature index is:  0 1.5 -1.0\n",
      "Info Gain is:  1.0 Best Feature index is:  0 1.0 0.0\n",
      "Info Gain is:  1.0 Best Feature index is:  0 1.0 0.0\n",
      "Info Gain is:  1.811278124459133 Best Feature index is:  0 0.8112781244591328 -1.0\n",
      "Info Gain is:  1.0 Best Feature index is:  0 1.0 0.0\n",
      "{'age': {'young': {'prescript': {'myope': {'astigmatic': {'yes': {'tearRate': {'normal': 'hard', 'reduced': 'no lenses'}}, 'no': {'tearRate': {'normal': 'soft', 'reduced': 'no lenses'}}}}, 'hyper': {'astigmatic': {'yes': {'tearRate': {'normal': 'hard', 'reduced': 'no lenses'}}, 'no': {'tearRate': {'normal': 'soft', 'reduced': 'no lenses'}}}}}}, 'presbyopic': {'prescript': {'myope': {'astigmatic': {'yes': {'tearRate': {'normal': 'hard', 'reduced': 'no lenses'}}, 'no': 'no lenses'}}, 'hyper': {'astigmatic': {'yes': 'no lenses', 'no': {'tearRate': {'normal': 'soft', 'reduced': 'no lenses'}}}}}}, 'pre': {'prescript': {'myope': {'astigmatic': {'yes': {'tearRate': {'normal': 'hard', 'reduced': 'no lenses'}}, 'no': {'tearRate': {'normal': 'soft', 'reduced': 'no lenses'}}}}, 'hyper': {'astigmatic': {'yes': 'no lenses', 'no': {'tearRate': {'normal': 'soft', 'reduced': 'no lenses'}}}}}}}}\n"
     ]
    }
   ],
   "source": [
    "fr = open('lenses.txt')\n",
    "lenses = [line.strip().split('\\t') for line in fr.readlines()]\n",
    "names = ['age', 'prescript', 'astigmatic', 'tearRate']\n",
    "myTree = createTree(lenses, names)\n",
    "print(myTree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
